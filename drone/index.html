<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Test</title>
  <style>body {background-color: black;}</style>
</head>
<body style='overflow: hidden; margin: 0;'>
  <canvas id='myCanvas' width=1000 height=500></canvas>
<script>

// EXPLANATION
// Up ahead are some function just for some reused things I'm doing
// The "main" animate function is on line 745

// Maybe I didn't use the activation function correctly?
// Maybe my rewards are off?

var c = document.getElementById("myCanvas");
let ctx = c.getContext("2d");

let windowWidth = window.innerWidth;
let windowHeight = window.innerHeight;

c.height = windowHeight;
c.width = windowWidth;

const plotHistory = [];

const stages = [
  [windowWidth*3/4,windowHeight/4],
  [windowWidth/4,windowHeight/4],
  [windowWidth*3/4,windowHeight*3/4],
  [windowWidth/3,windowHeight/5],
  [windowWidth*4/9,windowHeight*2/7]
]

function addVector(vec1, vec2) {
  return [vec1[0] + vec2[0], vec1[1] + vec2[1]]
}

function subVector(vec1, vec2) {
  return [vec1[0] - vec2[0], vec1[1] - vec2[1]]
}

function mulVector(vec1, vec2) {
  return [vec1[0] * vec2[0], vec1[1] * vec2[1]]
}

function divVector(vec1, vec2) {
  return [vec1[0] / vec2[0], vec1[1] / vec2[1]]
}

function minVector(vec1, vec2) {
  return [Math.min(vec1[0], vec2), Math.min(vec1[1], vec2)]
}

function lerp(A,B,t){
  return A+(B-A)*t;
}

function circle(x=50,y=50,rad=10,clr="orange") {
  ctx.beginPath();
  ctx.fillStyle = clr;
  ctx.arc(x,y, rad, 0, 2 * Math.PI);
  ctx.fill();
}

function line(x1=50,y1=50,x2=100,y2=100,clr="orange") {
  ctx.beginPath();
  ctx.strokeStyle = clr;
  ctx.lineWidth = 2;
  ctx.moveTo(x1,y1);
  ctx.lineTo(x2,y2);
  ctx.stroke();
}

function rect(x=50,y=50,w=10,h=10,clr="white") {
  ctx.beginPath();
  ctx.fillStyle = clr;
  ctx.rect(x,y, w,h);
  ctx.fill();
}

function text(x,y,text) {
  ctx.fillStyle = "white";
  ctx.globalAlpha = 1;
  ctx.font = "16px sans-serif";
  ctx.fillText(text, x,y);
}

function cross(v1,v2) {
  return v1[0] * v2[1] - v1[1] * v2[0];
}

class NN {
  constructor(layers) {

    this.layers = [];
    for (let neurons = 0; neurons < layers.length-1; neurons++) {
      this.layers.push(
        new Layer(layers[neurons], layers[neurons+1])
      )
    }

  }

  // ACTIVATION FUNCTIONS
  // Self explanitory
  static RELU(x) {
    return Math.max(0,x);
  }

  static tanh(x) {
    // console.log(x, x/200, Math.tanh(x), Math.tanh(x/200))
    // debugger
    return Math.tanh(x / 8);
  }

  static feedForward(initInputs, nn) {
    let outputs = Layer.feedForwardLayer(initInputs, nn.layers[0]);
    for (let layer = 1; layer < nn.layers.length; layer++) {
      var is_last_layer = layer == nn.layers.length;
      outputs = Layer.feedForwardLayer(outputs, nn.layers[layer], is_last_layer)
    }

    return outputs;
  }

  static mutate(network, mutation_factor=0.1) {
    // Implement new mutate like NEAT
    // New neuron, change weight, remove neuron, etc.
  }

  static mutate_better(network, mutationFactor = 0.1, mutationStep = 0.1) {
        network.layers.forEach(layer => {
            // Mutate biases
            for (let i = 0; i < layer.biases.length; i++) {
                if (Math.random() < mutationFactor) {
                    // layer.biases[i] += (Math.random() * 2 - 1) * 0.1; // used to be * mutationFactor

                    // Small random tweak or full reset
                    layer.biases[i] += (Math.random() * 2 - 1) * mutationStep;
                    if (Math.random() < 0.01) layer.biases[i] = Math.random() * 2 - 1; // occasional full mutation
                }
            }

            // Mutate weights
            for (let i = 0; i < layer.weights.length; i++) {
                for (let j = 0; j < layer.weights[i].length; j++) {
                    if (Math.random() < mutationFactor) {
                        // layer.weights[i][j] += (Math.random() * 2 - 1) * 0.1; // used to be  * mutationFactor

                        layer.weights[i][j] += (Math.random() * 2 - 1) * mutationStep;
                        if (Math.random() < 0.01) layer.weights[i][j] = Math.random() * 2 - 1; // occasional full mutation
                    }
                }
            }
        });
    }

  static crossover(dna1, dna2) {
    let child = JSON.parse(JSON.stringify(dna1)); // Deep copy parent1

    // Loop through each layer
    for (let i = 0; i < dna1.layers.length; i++) {
      let layer1 = dna1.layers[i];
      let layer2 = dna2.layers[i];
      let childLayer = child.layers[i];

      // Crossover biases (randomly pick from parent 1 or 2)
      for (let j = 0; j < layer1.biases.length; j++) {
        childLayer.biases[j] = Math.random() < 0.5 ? layer1.biases[j] : layer2.biases[j];
      }

      // Crossover weights more randomly
      for (let j = 0; j < layer1.weights.length; j++) {
            for (let k = 0; k < layer1.weights[j].length; k++) {
                childLayer.weights[j][k] = Math.random() < 0.5
                    ? layer1.weights[j][k]
                    : layer2.weights[j][k];
            }
        }
    }

    return child;
  }
  
  static createChild(dna1, dna2, p1_f, p2_f, i) {
    let child = NN.crossover(dna1, dna2);
    const mutation_proba = 1.0 / (Math.sqrt(p1_f + p2_f));
    // const mutation_proba = 0.01;
    // console.log(mutation_proba)
    NN.mutate_better(child, mutation_proba);
    return child;
  }


  // Visualise the neural network.
  // Used for best agent.
  static visualize(network, inputs) {
    var max_height = 150;
    const offset = 20;
    const between = 75;
    rect(offset-offset,offset,(between*network.layers.length)+offset*5,max_height,"gray")

    for (var layer = 0; layer < network.layers.length; layer++) {
     
      for (var neuronInput = 0; neuronInput < network.layers[layer].inputs.length; neuronInput++) {
        var x1= offset+between*layer;
         
        var y1= offset+(max_height/network.layers[layer].inputs.length)*neuronInput+(max_height/network.layers[layer].inputs.length/2);

        ctx.globalAlpha = Math.min(network.layers[layer].inputs[neuronInput],1);
        circle(x1, y1);
       
        for (var outputNeuron = 0; outputNeuron < network.layers[layer].outputs.length; outputNeuron++) {

          var x= offset+between*(layer+1);
          var y= offset+(max_height/network.layers[layer].outputs.length)*outputNeuron+(max_height/network.layers[layer].outputs.length/2);

          ctx.globalAlpha = Math.min(network.layers[layer].outputs[outputNeuron]+.1,1);
          circle(x, y);

          var x2 = offset+between*(layer+1)
          var y2 = offset+(max_height/network.layers[layer].outputs.length)*outputNeuron+(max_height/network.layers[layer].outputs.length/2);
          var weight = network.layers[layer].weights[neuronInput][outputNeuron]
          var color = weight>=0 ? "orange" : "blue"
          var thickness = (weight+1)/2;
          ctx.globalAlpha = thickness;
          line(x1,y1,x2,y2,color);
        }
      }


    }

    // 0 UP
    // 1 LEFT
    // 2 RIGHT
    // 3 DOWN

    var a = max_height/network.layers[network.layers.length-1].outputs.length

    text(
      (network.layers.length)*between+offset*2,
      (a)+offset/1.5,
      "UP"
    )

    text(
      (network.layers.length)*between+offset*2,
      (a*2)+offset/1.5,
      "LEFT"
    )

    text(
      (network.layers.length)*between+offset*2,
      (a*3)+offset/1.5,
      "RIGHT"
    )

    text(
      (network.layers.length)*between+offset*2,
      (a*4)+offset/1.5,
      "DOWN"
    )
  }


  // PLOT FUNCTION
  // For the graph up top.
  // It's jank, bad, and is kind of offset now and then and goes off screen if left for too long.
  // But it works.
  static plot(fitness, push=false) {
    if (push) plotHistory.push(fitness);
   
    if (plotHistory.length === 0) return; // Prevent plotting if there are no points

    const max = Math.max(...plotHistory);
    const min = Math.min(...plotHistory);
    const plotWidth = 400;
    const plotHeight = 200;
    const offset = 50;
    const plotX = windowWidth - offset - plotWidth;

    // Clear the previous plot
    rect(plotX, 20, plotWidth, plotHeight, "white");
    line(plotX + 20, 20 + 20, plotX + 20, plotHeight, "black");
    line(plotX + 20, plotHeight, plotX + plotWidth - 25, plotHeight, "black");

    const scalingFactor = (plotHeight - 40) / (max - min);

    // Iterate through points and draw the lines
    for (let i = 0; i < plotHistory.length - 1; i++) {
        const x1 = plotX + (plotWidth / (plotHistory.length - 1)) * i;
        const y1 = (plotHeight - ((plotHistory[i] - min) * scalingFactor));
       
        const x2 = plotX + (plotWidth / (plotHistory.length - 1)) * (i + 1);
        const y2 = (plotHeight - ((plotHistory[i + 1] - min) * scalingFactor));
       
        line(x1, y1, x2, y2, "black");
    }
  }

}


// LAYER
class Layer {
  constructor(inputNeurons, outputNeurons) {
    this.inputs = new Array(inputNeurons);
   
    this.outputs = new Array(outputNeurons);
    this.biases = new Array(outputNeurons);

    this.weights = [];
    for (var i = 0; i<inputNeurons; i++) {
      this.weights[i] = new Array(outputNeurons);
    }

    Layer.random(this);

  }

  static random(layer) {
    for (let i = 0; i < layer.inputs.length; i++) {
      for (let j = 0; j < layer.outputs.length; j++) {
        layer.weights[i][j] = Math.random()*2-1;
      }
    }

    for (let i = 0; i < layer.biases.length; i++) {
      layer.biases[i] = Math.random()*2-1;
    }
  }

  static feedForwardLayer(inputs, layer, binary=false) {
    for (let i = 0; i < layer.inputs.length; i++) {
      layer.inputs[i] = inputs[i]
    }

    for (let outputN = 0; outputN < layer.outputs.length; outputN++) {

      let sum = 0;
      for (let inputN = 0; inputN < layer.inputs.length; inputN++) {
        sum += layer.inputs[inputN]*layer.weights[inputN][outputN];
      }

      // If not binary (such as hidden layers) use tanh
      if (!binary) {
        // tanh
        layer.outputs[outputN] = NN.tanh(sum+layer.biases[outputN])
     
      // Use binary for outputs since for them it has to be either a 0 or 1.
      } else {
        // Binary Class
        // Same as lectures.
        // if (sum>layer.biases[outputN]) {
        //   layer.outputs[outputN]=1;
        // } else {
        //   layer.outputs[outputN]=0;
        // }

        // In drones, don't do tanh
        // skip this
        layer.outputs[outputN] = sum+layer.biases[outputN]
      }

    }

    return layer.outputs;
  }
}


// AGENT
// Renders a ball, stores brain, and updates based off outputs.
// thanks to Pezza for most of this code/inspiration (Pezzza's Work on YT)

class drone {
  constructor(
    x=Math.random()*windowWidth/2+windowWidth/4,
    y=Math.random()*windowHeight/2+windowHeight/4
  ) {
    this.pos = [x,y];
    this.vel = [0,0];
    this.acc = [0,0];

    this.width = 75;
    this.height = 25;
    
    this.angle = 0;
    this.angular_velocity = 0;

    this.stage = 0;
    this.time = 0;
    this.goalball = new goal();
    this.goalball.pos = stages[this.stage];

    this.dead = false;


    // Each drone will have 2 thrusters
    this.thrusters = [
      new thruster(this.pos[0]-this.width/2, this.pos[1]),
      new thruster(this.pos[0]+this.width/2, this.pos[1])
    ]
   
    this.color = "gray";
   
    this.fitness = 0;

    // Brain is a neural network with 4 inputs, 2 hidden layers of size 4 each, and 4 outputs.
    // INPUTS: to target x/y, vel x/y, cos angle of drone, sin angle of drone, angular velocity of drone
    // OUTPUTS: 4 values representing power/angle.
    const brain = [7, 9, 9, 4];
    // const randomLength = Math.floor(Math.random() * 3) + 3;
    // const randomNeurons = Math.floor(Math.random() * 5) + 4;
    // let brain = new Array(randomLength).fill(0).map(() => Math.floor(Math.random() * randomNeurons) + 2);
    // brain[0] = 7;
    // brain[brain.length-1] = 4;
    // console.log(brain)

    this.brain = new NN(brain);
    // console.log(this.brain)
  }

  move(i, goalpos) {
    // 0 UP
    // 1 LEFT
    // 2 RIGHT
    // 3 DOWN // NO MORE

    // Add acceleration
    // if (i[0]) this.acc[1]=speed;//this.fitness -= .01; // make this speed -speed for correctness
    // if (i[1]) this.acc[0]=speed;//this.fitness -= .01;
    // if (i[2]) this.acc[0]=-speed;//this.fitness -= .01;
    // if (i[3]) this.acc[1]=-speed;//this.fitness -= .01; // make this speed: speed for correctness



    // New Inputs:
    // 0: Power for thruster 0 (0 => 1)
    // 1: Angle for thruster 0 (-1 => 1)
    // 2: Power for thruster 0 (0 => 1)
    // 3: Angle for thruster 0 (-1 => 1)

    // SEND ALL THIS TO THRUSTERS
    const left = this.thrusters[0]
    const right = this.thrusters[1]

    left.setPower(i[0]);
    left.setAngle(i[1]);

    right.setPower(i[2]);
    right.setAngle(i[3]);

    // console.log(this.getThrust())

    // gravity
    this.acc[1] = .05;

    this.vel[0] += this.getThrust()[0];
    this.vel[1] += this.getThrust()[1];

    this.angular_velocity += this.getTorque();
		this.angle += this.angular_velocity;

    // normalize angle
    this.angle %= Math.PI * 2;

    // Update velocity
    this.vel[0] += this.acc[0];
    this.vel[1] += this.acc[1];

    // this.vel[0] *= .99; // Friction
    // this.vel[1] *= .99; // Friction

    // this.fitness -= Math.abs(this.vel[0])*10; // Penalize high velocity
    // this.fitness -= Math.abs(this.vel[1])*10; // Penalize high velocity


    // Max velocity
    // var maxSpeed = 5;
    // this.vel[0] = Math.min(Math.max(this.vel[0], -maxSpeed), maxSpeed);
    // this.vel[1] = Math.min(Math.max(this.vel[1], -maxSpeed), maxSpeed);


    // Update position
    this.pos[0] += this.vel[0];
    this.pos[1] += this.vel[1];

    // If velocity away from goal, penalize
    const goalx = goalpos[0];
    const goaly = goalpos[1];
    // if (goalx - (this.vel[0] + this.pos[0]) < goalx - this.pos[0] && goalx - (this.vel[1] + this.pos[1]) < goaly - this.pos[1]) {
    //   this.fitness += .5;
    // } else {
    //   this.fitness -= .5;
    // }

    // this.fitness += .1;

    // if ((i[0] && i[1]) || (i[0] && i[2])) this.fitness -= 10;
    // if ((i[3] && i[1]) || (i[3] && i[2])) this.fitness -= 10;
    // this.fitness -= 0.1 * (Math.abs(this.vel[0]) + Math.abs(this.vel[1]));

  }

  update() {

    // Keep the thrusters on the drone
    // this.thrusters[0].pos = [this.pos[0]-this.width/2, this.pos[1]]
    // this.thrusters[1].pos = [this.pos[0]+this.width/2, this.pos[1]]

    // difference in x and y
    this.goalball.pos = stages[this.stage];
    const goalx = this.goalball.pos[0];
    const goaly = this.goalball.pos[1];
    const dx = goalx - this.pos[0];
    const dy = goaly - this.pos[1];

    // Penalize if too far
    // this.fitness -= Math.sqrt( dx**2 + dy**2 );

    // Penalize for high angular velocity
    // this.fitness -= this.angular_velocity;

    // INPUTS: to target x/y, vel x/y, cos angle of drone, sin angle of drone, angular velocity of drone
    this.move(NN.feedForward([
      dx, dy, //to target x/y
      this.vel[0], this.vel[1], //vel x/y
      Math.cos(this.angle), Math.sin(this.angle), // cos angle of drone, sin angle of drone
      this.angular_velocity, // angular velocity of drone
    ], 
    this.brain), [goalx, goaly]);
    // console.log(NN.feedForward([normalizedX, normalizedY, goalx/windowWidth, goaly/windowHeight], this.brain));
    // console.log(this.brain)
  }

  getTorque() {
    const inertia_coef = .8;
    const thruster_offset = this.width/2;

		const angle_left =  -this.thrusters[0].angle - (Math.PI/2);
    const left_torque = this.thrusters[0].getPower() / thruster_offset * 
    cross(
      [Math.cos(angle_left), Math.sin(angle_left)], 
      [1.0, 0.0]
    );

		const angle_right = this.thrusters[1].angle - (Math.PI/2);
    const right_torque = this.thrusters[1].getPower() / thruster_offset * 
    cross(
      [Math.cos(angle_left), Math.sin(angle_left)], 
      [-1.0, 0.0]
    );


		return (left_torque + right_torque) * inertia_coef;
  }

  getThrust() {
    const left = this.thrusters[0];
    const right = this.thrusters[1];

		const angle_left = this.angle + left.angle - (Math.PI/2);
	  const thrust_left = mulVector([left.getPower(), left.getPower()], [Math.cos(angle_left), Math.sin(angle_left)]);

		const angle_right = this.angle + right.angle - (Math.PI/2);
		const thrust_right = mulVector([right.getPower(), right.getPower()], [Math.cos(angle_right), Math.sin(angle_right)]);

    // debugger
		return addVector(thrust_left, thrust_right);
	}

  draw() {
    ctx.save();

    ctx.translate(this.pos[0], this.pos[1])

    ctx.rotate(this.angle);

    ctx.fillStyle = this.color;
    rect(-this.width/2, -this.height/2, this.width, this.height);

    this.thrusters[0].draw([-this.width/2, 0]);
    this.thrusters[1].draw([+this.width/2, 0]);

    ctx.restore();
  }
}

const flame = new Image()
flame.src = "flame.png"

class thruster {
  constructor(x,y) {
    this.pos = [x,y];

    this.power_ratio = 0; // output of AI will be 0-1; so from 0 to max_power
    this.max_power = .25; // acc

		this.angle = 0; // Angle of each thruster
		this.max_angle = 0.5 * Math.PI; // Max left half PI and max right half PI
		this.target_angle;
		this.angle_var_speed = .0001; // How fast the thruster can rotate
		this.angle_ratio;

    this.width = 20;
    this.height = 50;
  }

  setAngle(ratio) {
    this.target_angle = this.max_angle * Math.max(-1.0, Math.min(1.0, ratio));
  }

  setPower(ratio) {
    this.power_ratio = Math.max(0.0, Math.min(1.0, ratio));
  }

  getPower() {
    return this.power_ratio * this.max_power;
  }

  update() {
    const speed = this.angle_var_speed;
    this.angle += speed * (this.target_angle - this.angle);
    this.angle_ratio = this.angle / this.max_angle;
  }

  draw(pos) {
    ctx.save();

    ctx.translate(pos[0], pos[1])
    
    ctx.rotate(this.target_angle);
    // Main thruster body
    rect(
      -this.width/2, 
      -this.height/2, 
      this.width, 
      this.height, 
      "gray"
    )


    // Flame
    ctx.translate(-this.width*2/2, +this.height/2.5)
    ctx.drawImage(flame, 0, 0, this.width*2, this.getPower()*flame.height/2)

    ctx.restore();

  }


}

// Simple dot on screen for posision.
// Doesn't need to be a class.
class goal {
  constructor() {
    /*
    this.pos = [
      Math.random() * windowWidth,
      Math.random() * windowHeight
    ];
    */

    this.pos = [
      windowWidth*3/4,
      windowHeight/4
    ];
  }

  draw() {
    ctx.beginPath();
    ctx.fillStyle = "green";
    ctx.arc(this.pos[0], this.pos[1], 5, 0, 2 * Math.PI);
    ctx.fill();
  }
}


// Initialize agents array, configure amount of agents, and the generation function.
var drones = [];
const training = true;
const ballAmount = training ? 4000 : 1;
function generation() {
  const drones_amount = drones.length;
  for (let i = 0; i < ballAmount-drones_amount; i++) {
    // let x = Math.random() * windowWidth;
    // let y = Math.random() * windowHeight;
    // drones.push(new drone(x, y));
    drones.push(new drone(windowWidth/2, windowHeight/2));
  }
}

// Generate first gen.
generation()

// Assign goal, purely for visuals, and for fitness calculation.
var goalball = new goal()


// Config
let steps_per_gen = 2000;
let gen = 0;
let step = 0;

if (!training) {
  document.addEventListener('mousemove', function(e) {
    goalball.pos[0] = e.clientX - 7;
    goalball.pos[1] = e.clientY - 7;
  });
}


// if (!localStorage.getItem("brain")) localStorage.setItem('brain', "{\"fitness\":-79852.91506666942,\"brain\":{\"layers\":[{\"inputs\":[-0.02137174119843621,0.11099622936126252,-0.047879122394246666,-0.004123451061363657],\"outputs\":[0.04931056500175949,-0.10153612454556875,0.09667762643373178,0.03153184985728907,-0.08675046323523979,-0.002488756048168393,0.1024036603526007],\"biases\":[0.04095441548424866,-0.11350061844515014,0.09921157064924271,0.024268035069157836,-0.08979267659397498,0.003162736088979263,0.09667388679275374],\"weights\":[[-0.0006481733497199751,-0.045717197386417566,0.09451767505950141,-0.0007320629529811609,0.018331140029499447,-0.019045928977273415,-0.08868185055452045],[0.031612289497859124,0.12428124949197214,-0.01687123665420824,0.013429824610282718,-0.050785071498858865,0.005683015333104701,0.02413011496819181],[-0.09656842458117418,0.06963798039537848,-0.03644955117212821,-0.1033112300043343,-0.1824974942569167,0.13273830573952486,-0.03820928891135767],[-0.060596260436669235,-0.04263101854571571,0.02026557991616553,-0.19922994009095646,-0.027769872455340027,0.0809859561873496,0.07592413618220721]]},{\"inputs\":[0.04931056500175949,-0.10153612454556875,0.09667762643373178,0.03153184985728907,-0.08675046323523979,-0.002488756048168393,0.1024036603526007],\"outputs\":[0.08593125632812669,0.08975491778397822,0.01513805087256934,-0.0474724743664328,0.013065817010262236,0.006560952589577505,0.03735551200343421],\"biases\":[0.10060191564581851,0.0750077378759982,0.015094358449828864,-0.03627741261013865,0.011825881338341927,0.00647039897776997,0.03215207375391765],\"weights\":[[-0.007465685024560383,0.015939796315605676,0.0015353599478004718,-0.04920817467408902,0.013451206094227435,0.014645338023631195,-0.06704742022722411],[0.08807504438553841,0.0710020403045861,0.023371662593475673,0.11438271661138255,0.06394951445018819,-0.028085447415192706,-0.05663348715307049],[0.03304720284773742,0.10269676530807391,0.013114103585590576,-0.019524453968723127,0.040333386793709534,-0.03925351178964188,-0.012627658824033333],[0.049565134001931584,0.0006983659457811156,0.09334001682283533,-0.07315821432291264,0.06953594479347054,0.030213084302871025,0.006546351775161597],[0.06135565632966065,-0.04827298699234826,0.03112347552259101,-0.012092774627974588,-0.015547354854684305,0.07186779004576392,0.017466658265330354],[0.022849036091134183,-0.02566045478149357,-0.14022760186209926,0.024664561361443373,0.036515946713025375,-0.04934413129225954,0.014067613165421535],[-0.04419352758757091,0.0704132705673496,0.004708497029700486,0.05875191045253982,-0.002726616132706979,0.05342397763225214,0.05215902377746635]]},{\"inputs\":[0.08593125632812669,0.08975491778397822,0.01513805087256934,-0.0474724743664328,0.013065817010262236,0.006560952589577505,0.03735551200343421],\"outputs\":[1,1,0,1],\"biases\":[-0.05361388392075887,-0.020539873297679676,-0.009339673241524744,-0.010949945805380173],\"weights\":[[0.038729825968166834,0.003331361273977622,-0.0713988383250234,-0.021593381485938763],[0.029082446696769817,0.012692840990284712,0.009948980387291185,-0.06305064745566746],[-0.044311385410983006,-0.005922337940038113,-0.11280964396190278,-0.11164465348677138],[0.06271549576976718,-0.1343676545185808,0.02209361754321169,-0.0077261927960031096],[0.028632462026410975,-0.010271652856849538,-0.004605139810650052,-0.10668622302870821],[-0.007048046416734196,0.06136053186885656,-0.0425915739154361,-0.008118647472714804],[-0.02619672855260632,0.04822150638691121,-0.028542500563720388,-0.01535000200645547]]}]}}")
  
// if (!training) drones[0].brain = JSON.parse(localStorage.getItem("brain")).brain;
if (localStorage.getItem("brain") !== null) {
  drones[0].brain = JSON.parse(localStorage.getItem("brain")).brain;
}

let previousBestFitness = -Infinity;
let stagnation = 0;

let dead = 0;

function isMovingTowardsGoal(position, velocity, goal) {
  // Vector from position to goal
  const toGoal = [goal[0] - position[0], goal[1] - position[1]];

  // Dot product of velocity and toGoal vector
  const dot = velocity[0] * toGoal[0] + velocity[1] * toGoal[1];

  // If dot product > 0, the drone is moving toward the goal
  // return dot > 0;
  return dot;
}

// MAIN CODE PER FRAME FOR EACH OF THE AGENTS
function frame() {
  ctx.clearRect(0, 0, c.width, c.height);

  ctx.globalAlpha = 1;
  // ctx.globalAlpha = 0.3;
 
  // Loop through all agents to update/determine their fitness
  // for (const agent of drones) {
  for (var i = 0; i < drones.length; i++) {
    const agent = drones[i];
    if (agent.dead) continue;

    // agent.draw();
    agent.goalball.draw();

    if (training && !agent.dead) {
      // agent.fitness += 1 / (0.000001 + Math.sqrt(
      //     Math.pow(goalball.pos[0] - agent.pos[0], 2) +
      //     Math.pow(goalball.pos[1] - agent.pos[1], 2)
      // ))
      const distance = Math.sqrt((agent.goalball.pos[0] - agent.pos[0])**2 + (agent.goalball.pos[1] - agent.pos[1])**2);
      // agent.fitness += Math.exp(-distance * 0.1);  // 0.1 controls scaling
      
      // Reward for going towards the goalball
      const dot = isMovingTowardsGoal(agent.pos, agent.vel, agent.goalball.pos)
      agent.fitness += (1 / ( 1 + distance )) * dot
      
      // agent.fitness += agent.vel * dot;

      // agent.fitness -= Math.abs(agent.angular_velocity * 100); // Penalize angular velocity

      // reward for staying up right
      agent.fitness += Math.cos(agent.angle) / 2;



      // Reward for speed
      // agent.fitness += Math.abs(
      //   Math.sqrt(
      //     Math.pow(agent.vel[0], 2) +
      //     Math.pow(agent.vel[1], 2)
      //   ) * 0.5
      // );

      if (distance < 50) {
        agent.fitness += Math.pow(Math.cos(agent.angle)*10, 3)
        agent.time++;
        // agent.fitness += steps_per_gen - step;
        if (agent.time >= 200) {
          // steps_per_gen = Math.max(...drones.map(d => d.stage)) * 1000;
          step = 0;
          agent.time = 0;
          agent.stage += 1;
          agent.fitness *= 10;
        }
      } 
      if ((agent.pos[0] < 0-windowWidth/2 || agent.pos[0] > windowWidth+windowWidth/2 
      || agent.pos[1] < 0-windowHeight/2 || agent.pos[1] > windowHeight+windowWidth/2) || (agent.angle <= -Math.PI || agent.angle >= Math.PI)) {
        agent.dead = true;
        if ((agent.angle <= -Math.PI || agent.angle >= Math.PI)) {
          agent.fitness /= 10;
          // agent.fitness = 0
        } 
        dead++
      }

    } else {
      ctx.globalAlpha = 1;
      // NN.visualize(drones[0].brain)
    }
    
    // console.log(i)
    agent.update();
    agent.thrusters[0].update();
    agent.thrusters[1].update();

    // agent.draw();
    // console.log(agent)

    // agent.thrusters[0].setPower(0);
    // agent.thrusters[1].setPower(0);

    // agent.thrusters[0].setAngle(0);
    // agent.thrusters[1].setAngle(0);
    

  }
 
  drones[0].draw()
  drones[0].goalball.draw()
  
  
  // drones[0].draw();
 
  // Draw the main objective
  // goalball.draw();
   
  if (training) {
    // Finds best agents
    let bestAgents = (drones.toSorted((a,b) => b.fitness - a.fitness)).slice(0,500);
    // for (var agent of bestAgents) {
    for (var i = 0; i < 500; i++) {
      // const agent = bestAgents[i];\
      const agent = bestAgents[i];
      if (agent.dead) continue;
      agent.color = "#FFD700"
      agent.draw();
      // agent.goalball.draw();
      // i == 0 ? console.log(agent.normx, agent.normy, agent.fitness) : null
      // i == 0 ? console.log(agent.fitness) : null

      // make the color if #1: red, #2: green, #3: blue.
      // agent.color = i == 0 ? "red" : i == 1 ? "green" : "blue";
      // agent.draw();
    }
    
   
    // Visualized progress over all generations.
    // It's a hacky solution so it doesn't work quite alright.
    NN.visualize(bestAgents[0].brain, bestAgents[0].pos)
    NN.plot(bestAgents[0].fitness);

    // Handle generations
    // Count steps and record best agent in localstorage
    step++;
    // drones[0].draw()
    // step%10==0?console.log(Math.cos(drones[0].angle)):null
     
    // If the steps are max, next generation
    // Or if the fitness is better than a certain threshold, next generation.
    //let threshold = 0.90;
    //if (JSON.parse(localStorage.getItem("brain"))) threshold = JSON.parse(localStorage.getItem("brain")).fitness
    // || (bestAgents[0].fitness > threshold)    
    if(step>=steps_per_gen || dead == drones.length ) {

      // If brain if it doesn't exist, create.
      if (!localStorage.getItem("brain")) localStorage.setItem("brain", JSON.stringify(bestAgents[0]))
     
      // If agent did better than last time, save.
      // if (bestAgents[0].fitness > JSON.parse(localStorage.getItem("brain")).fitness ) {
        // localStorage.setItem("brain", JSON.stringify(bestAgents[0]))
      // }
      let storedBrain = JSON.parse(localStorage.getItem("brain"));
      if (!storedBrain || bestAgents[0].fitness > storedBrain.fitness) {
          localStorage.setItem("brain", JSON.stringify(bestAgents[0]));
      }

     
      gen++
      console.log(`Gen: ${gen}, best: ${bestAgents[0].fitness}`)

      // Adjust mutation rate adaptively
      // if (bestAgents[0].fitness <= previousBestFitness && stagnation >= 50) {
      //   mutation_factor = Math.min(mutation_factor * 1.05, 0.3); // Slightly increase if stuck
      //   stagnation++;
      // } else {
      //   // mutation_factor *= 0.995; // Decrease normally if improving
      //   mutation_factor = Math.max(0.001, Math.min(0.3, 1 / (bestAgents[0].fitness + 1)));  // Keep in bounds
      //   stagnation = 0;
      // }
      // previousBestFitness = bestAgents[0].fitness;

      // Get best agents from last gen to stay
      const numBest = Math.floor(drones.length * 0.3);
      // Only half of best get best brain to ensure diversity.
      for (let i = 1; i < Math.floor(numBest/2); i++) {
        drones[i].brain = bestAgents[0].brain;
        // drones[i].brain = JSON.parse(localStorage.getItem("brain")).brain;
      }
 
      // Reset steps and remove all agents.
      step = 0;
      drones = drones.splice(numBest);
     
      // Plot the new generation best agent.
      NN.plot(bestAgents[0].fitness, true);
     
      // Generate new generation.
      generation();

      // Decrease mutation factor.
      // if (mutation_factor <= 0.01) mutation_factor = 0.01;
      // else mutation_factor -= 0.001;
      // mutation_factor *= 0.995; // Decrease by 0.5% per generation

      // Change goal pos
      goalball.pos = [Math.random() * windowWidth, Math.random() * windowHeight]
     
      // Get best agents from last gen to stay.
      // drones[0].brain = JSON.parse(localStorage.getItem("brain")).brain;
      for (let i = 0; i < bestAgents.length; i++) {
        if (bestAgents[i].fitness < drones[i].fitness) drones[i].brain = bestAgents[i].brain;
      }
      // if (bestAgents[1].fitness > drones[1].fitness) drones[1].brain = bestAgents[1].brain;
      // if (bestAgents[2].fitness > drones[2].fitness) drones[2].brain = bestAgents[2].brain;


      // Function to pick parents using weighted probability
      function selectParent(bestAgents) {
        let totalFitness = bestAgents.reduce((sum, agent) => sum + agent.fitness, 0);
        let pick = Math.random() * totalFitness;
        let sum = 0;

        for (let agent of bestAgents) {
          sum += agent.fitness;
          if (sum >= pick) return agent;
        }
        return bestAgents[Math.floor(Math.random() * bestAgents.length)]; // Fallback: Random agent for diversity
      }

      // Mutate the rest with crossover
      for (let i = numBest/2; i < drones.length; i++) {
          let parent1 = selectParent(bestAgents);
          let parent2 = selectParent(bestAgents);

          // Ensure different parents
          if (parent1 === parent2) parent2 = selectParent(bestAgents);

          // Create a child with crossover and mutation
          drones[i].brain = NN.createChild(parent1.brain, parent2.brain, parent1.fitness, parent2.fitness, i);
      }


      // reset all drone positions and velocities.
      for (let i = 0; i < drones.length; i++) {
        drones[i].pos = [windowWidth/2, windowHeight/2];
        drones[i].vel = [0, 0];
        drones[i].acc = [0, 0];
        drones[i].angle = 0;
        drones[i].angular_velocity = 0;
        drones[i].fitness = 0;
        drones[i].stage = 0;
        drones[i].time = 0;
        drones[i].dead = false;
      }
      dead = 0;

      // Mutate the rest.
      // for (let i = 3; i < drones.length; i++) {
      //   drones[i].brain = JSON.parse(JSON.stringify(drones[i%bestAgents.length].brain));
        
      //   // const mutation_proba = 1.0 / Math.sqrt(drones[i&bestAgents.length].fitness);
      //   NN.mutate(drones[i].brain, mutation_factor)
      //   // NN.mutate(drones[i].brain, mutation_proba)
      // }
    }
  }

  window.requestAnimationFrame(frame);
}
 
// setInterval(frame,50)
window.requestAnimationFrame(frame);
 
</script>

</body>
</html>